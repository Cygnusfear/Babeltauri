use crate::model::LanguagePair;
use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};

const OPENROUTER_URL: &str = "https://openrouter.ai/api/v1/chat/completions";
const LLM_MODEL: &str = "google/gemini-2.5-flash";

#[derive(Serialize)]
struct ChatMessage {
    role: String,
    content: String,
}

#[derive(Serialize)]
struct ChatRequest {
    model: String,
    messages: Vec<ChatMessage>,
    temperature: f64,
}

#[derive(Deserialize)]
struct ChatResponse {
    choices: Vec<Choice>,
}

#[derive(Deserialize)]
struct Choice {
    message: ResponseMessage,
}

#[derive(Deserialize)]
struct ResponseMessage {
    content: String,
}

pub async fn translate(api_key: &str, pair: &LanguagePair, text: &str) -> Result<String> {
    let request = ChatRequest {
        model: LLM_MODEL.to_string(),
        messages: vec![
            ChatMessage {
                role: "system".to_string(),
                content: pair.prompt.clone(),
            },
            ChatMessage {
                role: "user".to_string(),
                content: text.to_string(),
            },
        ],
        temperature: 0.3,
    };

    let client = reqwest::Client::new();
    let response = client
        .post(OPENROUTER_URL)
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Content-Type", "application/json")
        .json(&request)
        .send()
        .await
        .context("Failed to send request")?;

    if !response.status().is_success() {
        let status = response.status();
        let body = response.text().await.unwrap_or_default();
        anyhow::bail!("API error: {} - {}", status, body);
    }

    let chat_response: ChatResponse = response.json().await.context("Failed to parse response")?;

    chat_response
        .choices
        .first()
        .map(|c| c.message.content.clone())
        .context("No translation returned")
}
